import re, json, hashlib
from pathlib import Path
from typing import List, Tuple

# ==============================================================================
# 1. Cáº¤U HÃŒNH Há»† THá»NG
# ==============================================================================
SCRIPT_DIR = Path(__file__).parent.resolve()
RAW_TXT_DIR = SCRIPT_DIR / "../../data/raw"
OUT_DIR_REASONING = SCRIPT_DIR / "../../data/corpus_reasoning" # Kho BÃ¡c sÄ©
OUT_DIR_ADVICE    = SCRIPT_DIR / "../../data/corpus_advice"    # Kho Counselor

for p in [OUT_DIR_REASONING, OUT_DIR_ADVICE]:
    p.mkdir(parents=True, exist_ok=True)

# Cáº¥u hÃ¬nh cáº¯t Ä‘oáº¡n
CHUNK_TARGET = 200  
CHUNK_MAX    = 350  # Ná»›i rá»™ng Ä‘á»ƒ giá»¯ trá»n váº¹n danh sÃ¡ch A, B, C

ALLOW_CONDITIONS = set()

# ==============================================================================
# 2. Bá»˜ NHáº¬N DIá»†N (METADATA EXTRACTOR)
# ==============================================================================

def detect_source_from_file(name: str, content_sample: str) -> Tuple[str, str]:
    n = name.lower()
    c = content_sample.lower()
    if "mhgap" in n or "mh gap" in c: return "WHO mhGAP-IG 2023", "https://www.who.int/"
    if "icd11" in n or "icd-11" in n: return "WHO ICD-11", "https://icd.who.int/"
    if "dsm" in n: return "DSM-5", "https://psychiatry.org/"
    return "Everyday Essentials", ""

COND_HINTS = {
    "depress": "Depression", "anxiety": "Anxiety", "gad": "Anxiety",
    "panic": "Anxiety", "ptsd": "PTSD", "ocd": "OCD",
    "insomnia": "Sleep", "sleep": "Sleep", "substance": "SubstanceUse",
    "eating": "Eating", "suicid": "SuicideRisk", "self-harm": "SuicideRisk",
}
def infer_condition(file_name: str) -> str:
    n = file_name.lower()
    for k, v in COND_HINTS.items():
        if k in n: return v
    return "General"

# Tá»ª KHÃ“A PHÃ‚N LOáº I
CLINICAL_SECTIONS = {
    "risk_safety": ["risk", "safety", "self-harm", "suicid", "crisis", "urgent", "danger", "emergency"],
    "screening_cues": ["screen", "assessment", "identify", "symptom", "criteria", "evaluate", "diagnos"],
    "referral": ["refer", "specialist", "urgent referral", "follow-up", "escalate"],
    "management": ["management", "treatment", "therapy", "cognitive", "antidepressant", "medication"],
    "psychoeducation": ["psychoeducation", "advice", "support", "self-help", "education"],
}
EVERYDAY_TOPICS = {
    "sleep": ["sleep", "insomnia", "sleep hygiene", "bedtime"],
    "stress": ["stress", "tension", "overwhelm", "relaxation", "breathing"],
    "study": ["study", "exam", "focus", "procrastination"],
    "work": ["work", "burnout", "deadline", "overwork"],
    "relationships": ["relationship", "family", "partner", "friends", "conflict"],
    "emotions": ["grief", "loss", "sadness", "lonely", "anger"]
}
ADVICE_SECTIONS = {
    "coping_skill": ["breath", "relax", "grounding", "mindfulness", "journaling", "reappraisal", "exercise"],
    "communication_tips": ["i-statement", "assertive", "boundary", "active listening"],
    "habits": ["sleep hygiene", "pomodoro", "time management", "routine", "schedule", "habit"]
}

# Tá»ª ÄIá»‚N Dá»ŠCH THUáº¬T MINI
GLOSS_MAP = {
    "depression":"tráº§m cáº£m","anxiety":"lo Ã¢u","suicide":"tá»± sÃ¡t","self-harm":"tá»± háº¡i",
    "ideation":"Ã½ nghÄ©","risk":"nguy cÆ¡","safety":"an toÃ n","screening":"sÃ ng lá»c",
    "assessment":"Ä‘Ã¡nh giÃ¡","referral":"chuyá»ƒn tuyáº¿n","psychoeducation":"giÃ¡o dá»¥c tÃ¢m lÃ½",
    "support":"há»— trá»£","urgent":"kháº©n cáº¥p","sleep":"giáº¥c ngá»§","hygiene":"vá»‡ sinh giáº¥c ngá»§",
    "stress":"cÄƒng tháº³ng","breathing":"hÃ­t thá»Ÿ","grounding":"neo tÃ¢m trÃ­","mindfulness":"chÃ¡nh niá»‡m",
    "communication":"giao tiáº¿p","boundary":"ranh giá»›i","assertive":"quáº£ quyáº¿t",
    "study":"há»c táº­p","work":"cÃ´ng viá»‡c","burnout":"kiá»‡t sá»©c"
}

def normalize(text: str) -> str:
    text = re.sub(r"\s+", " ", text)
    text = re.sub(r"(^|\s)page\s*\d+(\s*of\s*\d+)?", " ", text, flags=re.I)
    return text.strip()

def detect_axes(text: str):
    tl = text.lower()
    clinical = [sec for sec, keys in CLINICAL_SECTIONS.items() if any(k in tl for k in keys)]
    life_topics = [tpc for tpc, keys in EVERYDAY_TOPICS.items() if any(k in tl for k in keys)]
    advice = [sec for sec, keys in ADVICE_SECTIONS.items() if any(k in tl for k in keys)]
    
    risk = "low"
    if any(k in tl for k in ["suicid", "self-harm", "kill myself", "end my life", "tá»± sÃ¡t", "tá»± tá»­", "cháº¿t"]):
        risk = "high"
    elif any(k in tl for k in ["crisis", "urgent", "danger", "emergency", "cáº¥p cá»©u"]):
        risk = "medium"

    return clinical, life_topics, advice, risk

def gloss_vi_short(text_en: str) -> str:
    sents = re.split(r"(?<=[\.\!\?])\s+", text_en.strip())
    pick = " ".join(sents[:2]) if sents else text_en
    low  = pick.lower()
    for en, vi in GLOSS_MAP.items():
        low = re.sub(rf"\b{re.escape(en)}\b", vi, low)
    low  = low[:1].upper() + low[1:]
    return (low[:220] + "...") if len(low) > 220 else low

def make_id(source: str, main_section: str, text: str) -> str:
    h = hashlib.sha1((main_section + text[:100]).encode()).hexdigest()[:8]
    src_tag = "mhgap" if "mhgap" in source.lower() else ("everyday" if "everyday" in source.lower() else "clinical")
    return f"{src_tag}#{main_section}_{h}"

# ==============================================================================
# 3. HÃ€M Cáº®T THÃ”NG MINH (STRUCTURE PRESERVING)
# ==============================================================================

def chunk_smart_preserve_structure(text: str) -> List[str]:
    """
    Giá»¯ nguyÃªn danh sÃ¡ch A. B. C. hoáº·c 1. 2. 3. Ä‘á»ƒ báº£o toÃ n logic cháº©n Ä‘oÃ¡n.
    """
    text = re.sub(r'[ \t]+', ' ', text)
    lines = text.split('\n')
    
    chunks = []
    current_chunk = []
    current_wc = 0
    
    list_pattern = re.compile(r'^\s*(\d+\.|[A-Z]\.|-|â€¢|\*)\s+')

    for line in lines:
        line = line.strip()
        if not line: continue
        wc = len(line.split())
        is_list_item = bool(list_pattern.match(line))
        
        if current_wc + wc <= CHUNK_TARGET:
            current_chunk.append(line)
            current_wc += wc
        elif is_list_item and (current_wc + wc <= CHUNK_MAX):
            current_chunk.append(line)
            current_wc += wc
        else:
            if current_chunk: chunks.append("\n".join(current_chunk))
            overlap = current_chunk[-2:] if len(current_chunk) > 2 else current_chunk[-1:]
            current_chunk = overlap + [line]
            current_wc = sum(len(l.split()) for l in current_chunk)

    if current_chunk: chunks.append("\n".join(current_chunk))
    return chunks

# ==============================================================================
# 4. MAIN LOOP: LOGIC Äá»ŠNH TUYáº¾N AN TOÃ€N (SAFETY ROUTING)
# ==============================================================================

def main():
    stats = {
        "reasoning": 0, 
        "advice": 0, 
        "high_risk_blocked": 0,
        "clinical_source_blocked": 0 
    }
    print(f"ğŸš€ Báº¯t Ä‘áº§u Routing V5 (DSM/ICD Hard Block)...")

    for path in sorted(RAW_TXT_DIR.glob("*.txt")):
        raw = path.read_text("utf-8", errors="ignore")
        sample = raw[:2000]
        source, url = detect_source_from_file(path.name, sample)
        condition = infer_condition(path.name)

        chunks = chunk_smart_preserve_structure(raw)

        for ch in chunks:
            clinical_sec, life_topics, advice_sec, risk_band = detect_axes(ch)

            if not (clinical_sec or life_topics or advice_sec):
                continue

            main_sec = (clinical_sec[0] if clinical_sec else (advice_sec[0] if advice_sec else "general"))
            title_en = f"{condition} â€” {main_sec.replace('_',' ').title()}"
            gloss_vi = gloss_vi_short(ch)
            sid = make_id(source, main_sec, ch)

            item = {
                "id": sid,
                "content": ch,
                "metadata": {
                    "source": source,
                    "url": url,
                    "condition": condition,
                    "risk_band": risk_band,
                    "topics": life_topics + advice_sec + clinical_sec,
                    "is_clinical": bool(clinical_sec),
                    "is_advice": False 
                },
                "index_text": f"{title_en} {ch} {gloss_vi}"
            }

            # ------------------------------------------------------
            # ğŸ›‘ QUY Táº®C AN TOÃ€N Cá»T LÃ•I (CORE SAFETY RULES)
            # ------------------------------------------------------
            
            # Biáº¿n cá» nháº­n diá»‡n nguá»“n Cháº©n Ä‘oÃ¡n thuáº§n tÃºy
            is_pure_diagnostic_source = "dsm" in source.lower() or "icd" in source.lower()

            # ğŸŸ¢ KHO 1: REASONING (BÃ¡c sÄ©) - LÆ°u táº¥t cáº£ nhá»¯ng gÃ¬ cÃ³ mÃ¹i Y khoa
            if clinical_sec or "who" in source.lower() or is_pure_diagnostic_source:
                subdir = OUT_DIR_REASONING / path.stem.lower()
                subdir.mkdir(exist_ok=True)
                with open(subdir / f"{sid}.json", "w", encoding="utf-8") as f:
                    json.dump(item, f, ensure_ascii=False, indent=2)
                stats["reasoning"] += 1

            # ğŸŸ  KHO 2: ADVICE (Counselor) - Chá»‰ lÆ°u Lá»i khuyÃªn An toÃ n
            has_advice_content = (advice_sec or life_topics or "psychoeducation" in clinical_sec)
            
            if has_advice_content:
                # ğŸ”’ RULE 1: CHáº¶N High Risk (Tá»± sÃ¡t -> KhÃ´ng khuyÃªn lung tung)
                if risk_band == "high":
                    stats["high_risk_blocked"] += 1
                    continue 

                # ğŸ”’ RULE 2: CHáº¶N Nguá»“n Cháº©n Ä‘oÃ¡n (DSM/ICD -> KhÃ´ng pháº£i lá»i khuyÃªn)
                # ÄÃ¢y lÃ  fix cho trÆ°á»ng há»£p ASD "Habit" báº¡n phÃ¡t hiá»‡n
                if is_pure_diagnostic_source:
                    stats["clinical_source_blocked"] += 1
                    continue

                # âœ… ÄÃ£ qua cÃ¡c chá»‘t cháº·n -> LÆ°u vÃ o Advice
                subdir = OUT_DIR_ADVICE / path.stem.lower()
                subdir.mkdir(exist_ok=True)
                
                item_advice = item.copy()
                item_advice["metadata"]["is_advice"] = True
                item_advice["id"] = f"adv_{sid}"
                
                with open(subdir / f"adv_{sid}.json", "w", encoding="utf-8") as f:
                    json.dump(item_advice, f, ensure_ascii=False, indent=2)
                stats["advice"] += 1

    print(f"="*50)
    print(f"ğŸ“Š THá»NG KÃŠ FINAL:")
    print(f"   âœ… Reasoning DB:    {stats['reasoning']} chunks (Gá»“m cáº£ DSM/ICD/mhGAP)")
    print(f"   âœ… Advice DB:       {stats['advice']} chunks (Sáº¡ch, an toÃ n)")
    print(f"   ğŸ›¡ï¸ Cháº·n High-Risk:  {stats['high_risk_blocked']} chunks")
    print(f"   ğŸ›¡ï¸ Cháº·n DSM/ICD:    {stats['clinical_source_blocked']} chunks (Loáº¡i bá» False Positive)")
    print(f"="*50)

if __name__ == "__main__":
    main()