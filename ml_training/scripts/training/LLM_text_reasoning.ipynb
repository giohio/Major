{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10b24c5f02bd488f9a30a5e41ef58db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36c73b3ea3274d8aa9358c8654f953cb",
              "IPY_MODEL_b6609e2efa684e23a5822e8f4f6e9ee3",
              "IPY_MODEL_2ffeb72a228f45469077cdca1de56383"
            ],
            "layout": "IPY_MODEL_0141bd13f85044a0a7fefd2cf5641d33"
          }
        },
        "36c73b3ea3274d8aa9358c8654f953cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ced41a55f14396b2cb609541871f12",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_121055da13ac48b5a4f6c4f49f3e5759",
            "value": "Map:‚Äá100%"
          }
        },
        "b6609e2efa684e23a5822e8f4f6e9ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9acd214dfe1a4bc191df37feba70d73d",
            "max": 5085,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d98d9486d10d4202b1e8ba7f5a1b32e2",
            "value": 5085
          }
        },
        "2ffeb72a228f45469077cdca1de56383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8317896d76a94da7bc00bd96a093d623",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f0003dd5ae0447ba1c3aad67bda2966",
            "value": "‚Äá5085/5085‚Äá[00:00&lt;00:00,‚Äá18896.75‚Äáexamples/s]"
          }
        },
        "0141bd13f85044a0a7fefd2cf5641d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ced41a55f14396b2cb609541871f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121055da13ac48b5a4f6c4f49f3e5759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9acd214dfe1a4bc191df37feba70d73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98d9486d10d4202b1e8ba7f5a1b32e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8317896d76a94da7bc00bd96a093d623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f0003dd5ae0447ba1c3aad67bda2966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a582eef10a448ef9b93b3a97cc119de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_905bf036a63341afa80d46cad0efc5ad",
              "IPY_MODEL_6467d887406942f7b30f6f155e90db53",
              "IPY_MODEL_bdb5cbfae01245c0a968f060fe4f3dca"
            ],
            "layout": "IPY_MODEL_010efd57cfdd43278550962dfcb22600"
          }
        },
        "905bf036a63341afa80d46cad0efc5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c11a1d6d7a4df4958303dc205e052f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f0ac118a42a746c7a1d49041bd8b51e9",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=6):‚Äá100%"
          }
        },
        "6467d887406942f7b30f6f155e90db53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dd0dcc5c16e4b97b1098f1abe33d2e6",
            "max": 5085,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c78eab6c1a5d4e529a29af97bd136834",
            "value": 5085
          }
        },
        "bdb5cbfae01245c0a968f060fe4f3dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebad4af77eb7455fbf4fa70caf4e3167",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7d1bf9882f274bc3babe261cffe05300",
            "value": "‚Äá5085/5085‚Äá[00:10&lt;00:00,‚Äá746.27‚Äáexamples/s]"
          }
        },
        "010efd57cfdd43278550962dfcb22600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89c11a1d6d7a4df4958303dc205e052f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ac118a42a746c7a1d49041bd8b51e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dd0dcc5c16e4b97b1098f1abe33d2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78eab6c1a5d4e529a29af97bd136834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebad4af77eb7455fbf4fa70caf4e3167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1bf9882f274bc3babe261cffe05300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezJAT5kVFfhq",
        "outputId": "9d7c955e-fd4c-4c11-f05a-d6c04db2bf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aEo2Qt8EX-z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# C√†i ƒë·∫∑t Unsloth v√† c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Load base model and configure LoRA\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ LOADING MODEL & CONFIGURING LORA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Configuration\n",
        "max_seq_length = 1024\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "model_name = \"unsloth/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "# Load base model\n",
        "print(f\"\\n‚¨áÔ∏è Loading {model_name}...\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")\n",
        "print(\"‚úÖ Base model loaded!\")\n",
        "\n",
        "# Configure LoRA\n",
        "print(\"\\nüîß Configuring LoRA adapters...\")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        ")\n",
        "print(\"‚úÖ LoRA adapters configured!\")\n",
        "print(f\"üìä Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ0ZMs1jIQGa",
        "outputId": "d63b3c46-9ec1-4681-ddae-bb09dac3de9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üöÄ LOADING MODEL & CONFIGURING LORA\n",
            "============================================================\n",
            "\n",
            "‚¨áÔ∏è Loading unsloth/Qwen2.5-1.5B-Instruct...\n",
            "==((====))==  Unsloth 2025.11.3: Fast Qwen2 patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "‚úÖ Base model loaded!\n",
            "\n",
            "üîß Configuring LoRA adapters...\n",
            "‚úÖ LoRA adapters configured!\n",
            "üìä Trainable parameters: 18,464,768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Load and format training data\n",
        "from datasets import load_dataset\n",
        "\n",
        "# System prompt (MUST match inference later!)\n",
        "SYSTEM_PROMPT = \"\"\"B·∫°n l√† m·ªôt AI Router th√¥ng minh trong h·ªá th·ªëng t∆∞ v·∫•n t√¢m l√Ω.\n",
        "Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n lo·∫°i c√¢u n√≥i c·ªßa ng∆∞·ªùi d√πng v√†o 1 trong 4 nh√£n sau:\n",
        "\n",
        "1. emotional_support: C·∫ßn an ·ªßi, t√¢m s·ª±, gi·∫£i t·ªèa c·∫£m x√∫c (VD: bu·ªìn, ch√°n, c√¥ ƒë∆°n).\n",
        "2. informational: H·ªèi ƒë·ªãnh nghƒ©a, ki·∫øn th·ª©c y khoa, th√¥ng tin thu·ªëc/b·ªánh.\n",
        "3. complex_consultation: Ca b·ªánh ph·ª©c t·∫°p, ƒëa tri·ªáu ch·ª©ng, c·∫ßn suy lu·∫≠n s√¢u.\n",
        "4. high_risk: C√≥ √Ω ƒë·ªãnh t·ª± s√°t, t·ª± h·∫°i, nguy hi·ªÉm t√≠nh m·∫°ng.\n",
        "\n",
        "Ch·ªâ tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON duy nh·∫•t: {\"label\": \"t√™n_nh√£n\"}\"\"\"\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    \"\"\"Format data in ChatML style\"\"\"\n",
        "    inputs = examples[\"text\"]\n",
        "    labels = examples[\"label\"]\n",
        "    texts = []\n",
        "\n",
        "    for input_text, label in zip(inputs, labels):\n",
        "        # ChatML format - CRITICAL!\n",
        "        prompt = f\"\"\"<|im_start|>system\n",
        "{SYSTEM_PROMPT}<|im_end|>\n",
        "<|im_start|>user\n",
        "{input_text}<|im_end|>\n",
        "<|im_start|>assistant\n",
        "{{\"label\": \"{label}\"}}<|im_end|>\"\"\"\n",
        "\n",
        "        texts.append(prompt)\n",
        "\n",
        "    return {\"text\": texts}\n",
        "\n",
        "# Load training data\n",
        "print(\"üìÇ Loading training data...\")\n",
        "train_file = \"/content/drive/MyDrive/Major/Text_Reasoning/Text_Reasoning_train.jsonl\"\n",
        "train_dataset = load_dataset(\"json\", data_files=train_file, split=\"train\")\n",
        "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(train_dataset)} training samples\")\n",
        "\n",
        "# Show sample\n",
        "print(\"\\nüìù Sample formatted prompt:\")\n",
        "print(\"-\"*60)\n",
        "print(train_dataset[0]['text'][:350])\n",
        "print(\"...\")\n",
        "print(\"-\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "10b24c5f02bd488f9a30a5e41ef58db1",
            "36c73b3ea3274d8aa9358c8654f953cb",
            "b6609e2efa684e23a5822e8f4f6e9ee3",
            "2ffeb72a228f45469077cdca1de56383",
            "0141bd13f85044a0a7fefd2cf5641d33",
            "b5ced41a55f14396b2cb609541871f12",
            "121055da13ac48b5a4f6c4f49f3e5759",
            "9acd214dfe1a4bc191df37feba70d73d",
            "d98d9486d10d4202b1e8ba7f5a1b32e2",
            "8317896d76a94da7bc00bd96a093d623",
            "5f0003dd5ae0447ba1c3aad67bda2966"
          ]
        },
        "id": "AbDybcoQJLQC",
        "outputId": "2b8cdb0a-e9fe-4369-9923-0f96a25fcf44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Loading training data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5085 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10b24c5f02bd488f9a30a5e41ef58db1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 5085 training samples\n",
            "\n",
            "üìù Sample formatted prompt:\n",
            "------------------------------------------------------------\n",
            "<|im_start|>system\n",
            "B·∫°n l√† m·ªôt AI Router th√¥ng minh trong h·ªá th·ªëng t∆∞ v·∫•n t√¢m l√Ω.\n",
            "Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n lo·∫°i c√¢u n√≥i c·ªßa ng∆∞·ªùi d√πng v√†o 1 trong 4 nh√£n sau:\n",
            "\n",
            "1. emotional_support: C·∫ßn an ·ªßi, t√¢m s·ª±, gi·∫£i t·ªèa c·∫£m x√∫c (VD: bu·ªìn, ch√°n, c√¥ ƒë∆°n).\n",
            "2. informational: H·ªèi ƒë·ªãnh nghƒ©a, ki·∫øn th·ª©c y khoa, th√¥ng tin thu·ªëc/b·ªánh.\n",
            "3. complex_consultation: Ca b·ªánh \n",
            "...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Train the model\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=10,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=not torch.cuda.is_bf16_supported(),\n",
        "    bf16=torch.cuda.is_bf16_supported(),\n",
        "    logging_steps=10,\n",
        "    optim=\"adamw_8bit\",\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    seed=3407,\n",
        "    output_dir=\"outputs\",\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,\n",
        "    args=training_args,\n",
        ")\n",
        "\n",
        "# Train!\n",
        "print(\"\\nüèÉ Training started...\")\n",
        "trainer_stats = trainer.train()\n",
        "print(\"\\nüéâ Training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0a582eef10a448ef9b93b3a97cc119de",
            "905bf036a63341afa80d46cad0efc5ad",
            "6467d887406942f7b30f6f155e90db53",
            "bdb5cbfae01245c0a968f060fe4f3dca",
            "010efd57cfdd43278550962dfcb22600",
            "89c11a1d6d7a4df4958303dc205e052f",
            "f0ac118a42a746c7a1d49041bd8b51e9",
            "9dd0dcc5c16e4b97b1098f1abe33d2e6",
            "c78eab6c1a5d4e529a29af97bd136834",
            "ebad4af77eb7455fbf4fa70caf4e3167",
            "7d1bf9882f274bc3babe261cffe05300"
          ]
        },
        "id": "zc0n1M9RJMsv",
        "outputId": "db876c4b-ec08-4b82-994f-789c58f7cb16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üöÄ STARTING TRAINING\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/5085 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a582eef10a448ef9b93b3a97cc119de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üèÉ Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 5,085 | Num Epochs = 1 | Total steps = 318\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 18,464,768 of 1,562,179,072 (1.18% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiennguyencodon1012\u001b[0m (\u001b[33mkiennguyencodon1012-hanoi-university-of-industry\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251121_020522-h0nklr1i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kiennguyencodon1012-hanoi-university-of-industry/huggingface/runs/h0nklr1i' target=\"_blank\">radiant-glitter-5</a></strong> to <a href='https://wandb.ai/kiennguyencodon1012-hanoi-university-of-industry/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/kiennguyencodon1012-hanoi-university-of-industry/huggingface' target=\"_blank\">https://wandb.ai/kiennguyencodon1012-hanoi-university-of-industry/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/kiennguyencodon1012-hanoi-university-of-industry/huggingface/runs/h0nklr1i' target=\"_blank\">https://wandb.ai/kiennguyencodon1012-hanoi-university-of-industry/huggingface/runs/h0nklr1i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, openai] in use.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [318/318 13:20, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.576900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.765200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.323000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.257600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.213800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.172000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.134100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.099100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.093400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.087200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.085400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.078600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.076000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.072000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.074300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.070500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.065600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.062900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéâ Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: Save trained model\n",
        "output_dir = \"/content/drive/MyDrive/Major/Text_Reasoning/qwen_psychology_router_lora\"\n",
        "\n",
        "print(f\"üíæ Saving model to: {output_dir}\")\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(\"‚úÖ Model saved successfully!\")\n",
        "\n",
        "# Verify files saved\n",
        "import os\n",
        "print(\"\\nüìÇ Saved files:\")\n",
        "for f in os.listdir(output_dir):\n",
        "    size = os.path.getsize(os.path.join(output_dir, f)) / (1024*1024)\n",
        "    print(f\"   {f:40} {size:>8.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPNTOE5vJRiu",
        "outputId": "249c7ec3-4b3c-4244-eb83-09054764c372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saving model to: /content/drive/MyDrive/Major/Text_Reasoning/qwen_psychology_router_lora\n",
            "‚úÖ Model saved successfully!\n",
            "\n",
            "üìÇ Saved files:\n",
            "   README.md                                    0.01 MB\n",
            "   adapter_model.safetensors                   70.49 MB\n",
            "   adapter_config.json                          0.00 MB\n",
            "   chat_template.jinja                          0.00 MB\n",
            "   tokenizer_config.json                        0.00 MB\n",
            "   special_tokens_map.json                      0.00 MB\n",
            "   added_tokens.json                            0.00 MB\n",
            "   vocab.json                                   2.65 MB\n",
            "   merges.txt                                   1.59 MB\n",
            "   tokenizer.json                              10.89 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Quick sanity check (3 predictions)\n",
        "from unsloth import FastLanguageModel\n",
        "import json\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üß™ QUICK SANITY CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Set to inference mode\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "def quick_predict(text):\n",
        "    \"\"\"Quick prediction function\"\"\"\n",
        "    prompt = f\"\"\"<|im_start|>system\n",
        "{SYSTEM_PROMPT}<|im_end|>\n",
        "<|im_start|>user\n",
        "{text}<|im_end|>\n",
        "<|im_start|>assistant\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=64, temperature=0.1, do_sample=False)\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    # Extract assistant response\n",
        "    try:\n",
        "        response = result.split(\"<|im_start|>assistant\")[-1].split(\"<|im_end|>\")[0].strip()\n",
        "        parsed = json.loads(response)\n",
        "        return parsed.get(\"label\", \"unknown\")\n",
        "    except:\n",
        "        return \"parse_error\"\n",
        "\n",
        "# Test\n",
        "test_cases = [\n",
        "    (\"Em bu·ªìn qu√°, v·ª´a chia tay\", \"emotional_support\"),\n",
        "    (\"Tr·∫ßm c·∫£m l√† g√¨?\", \"informational\"),\n",
        "    (\"Em mu·ªën ch·∫øt r·ªìi\", \"high_risk\"),\n",
        "]\n",
        "\n",
        "print(\"\\n\")\n",
        "for text, expected in test_cases:\n",
        "    pred = quick_predict(text)\n",
        "    status = \"‚úÖ\" if pred == expected else \"‚ùå\"\n",
        "    print(f\"{status} {text:40} ‚Üí {pred:25} (expected: {expected})\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è If all 3 passed, proceed to full evaluation!\")\n",
        "print(\"   If failed, check format or retrain.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPuIrMBXJUNl",
        "outputId": "4beb8147-4f07-4b75-8a5f-8c929d42f759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üß™ QUICK SANITY CHECK\n",
            "============================================================\n",
            "\n",
            "\n",
            "‚úÖ Em bu·ªìn qu√°, v·ª´a chia tay                ‚Üí emotional_support         (expected: emotional_support)\n",
            "‚úÖ Tr·∫ßm c·∫£m l√† g√¨?                          ‚Üí informational             (expected: informational)\n",
            "‚úÖ Em mu·ªën ch·∫øt r·ªìi                         ‚Üí high_risk                 (expected: high_risk)\n",
            "\n",
            "‚ö†Ô∏è If all 3 passed, proceed to full evaluation!\n",
            "   If failed, check format or retrain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: Load trained model for evaluation\n",
        "from unsloth import FastLanguageModel\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üîÑ LOADING MODEL FOR EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Paths\n",
        "BASE_MODEL = \"unsloth/Qwen2.5-1.5B-Instruct\"\n",
        "ADAPTER_PATH = \"/content/drive/MyDrive/Major/Text_Reasoning/qwen_psychology_router_lora\"\n",
        "\n",
        "# Load base model\n",
        "print(f\"üì• Loading base model: {BASE_MODEL}\")\n",
        "eval_model, eval_tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=BASE_MODEL,\n",
        "    max_seq_length=1024,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "# Load LoRA adapter\n",
        "print(f\"üì• Loading LoRA adapter: {ADAPTER_PATH}\")\n",
        "eval_model = PeftModel.from_pretrained(eval_model, ADAPTER_PATH)\n",
        "\n",
        "# Set inference mode\n",
        "FastLanguageModel.for_inference(eval_model)\n",
        "\n",
        "print(\"‚úÖ Model loaded and ready for evaluation!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S53DrW3JUh_",
        "outputId": "4491d5a8-04c4-49b0-a6ab-3d5b6a233168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üîÑ LOADING MODEL FOR EVALUATION\n",
            "============================================================\n",
            "üì• Loading base model: unsloth/Qwen2.5-1.5B-Instruct\n",
            "==((====))==  Unsloth 2025.11.3: Fast Qwen2 patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "üì• Loading LoRA adapter: /content/drive/MyDrive/Major/Text_Reasoning/qwen_psychology_router_lora\n",
            "‚úÖ Model loaded and ready for evaluation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: Define prediction function for evaluation\n",
        "import json\n",
        "import torch\n",
        "\n",
        "# System prompt (MUST be same as training!)\n",
        "SYSTEM_PROMPT = \"\"\"B·∫°n l√† m·ªôt AI Router th√¥ng minh trong h·ªá th·ªëng t∆∞ v·∫•n t√¢m l√Ω.\n",
        "Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n lo·∫°i c√¢u n√≥i c·ªßa ng∆∞·ªùi d√πng v√†o 1 trong 4 nh√£n sau:\n",
        "\n",
        "1. emotional_support: C·∫ßn an ·ªßi, t√¢m s·ª±, gi·∫£i t·ªèa c·∫£m x√∫c (VD: bu·ªìn, ch√°n, c√¥ ƒë∆°n).\n",
        "2. informational: H·ªèi ƒë·ªãnh nghƒ©a, ki·∫øn th·ª©c y khoa, th√¥ng tin thu·ªëc/b·ªánh.\n",
        "3. complex_consultation: Ca b·ªánh ph·ª©c t·∫°p, ƒëa tri·ªáu ch·ª©ng, c·∫ßn suy lu·∫≠n s√¢u.\n",
        "4. high_risk: C√≥ √Ω ƒë·ªãnh t·ª± s√°t, t·ª± h·∫°i, nguy hi·ªÉm t√≠nh m·∫°ng.\n",
        "\n",
        "Ch·ªâ tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON duy nh·∫•t: {\"label\": \"t√™n_nh√£n\"}\"\"\"\n",
        "\n",
        "def predict_intent(text):\n",
        "    \"\"\"\n",
        "    Predict intent for a single query\n",
        "    Returns: predicted_label (str)\n",
        "    \"\"\"\n",
        "    # Build ChatML prompt\n",
        "    prompt = f\"\"\"<|im_start|>system\n",
        "{SYSTEM_PROMPT}<|im_end|>\n",
        "<|im_start|>user\n",
        "{text}<|im_end|>\n",
        "<|im_start|>assistant\n",
        "\"\"\"\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = eval_tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        outputs = eval_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=64,\n",
        "            temperature=0.1,\n",
        "            do_sample=False,\n",
        "            use_cache=True,\n",
        "            pad_token_id=eval_tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    full_output = eval_tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    # Extract assistant response\n",
        "    try:\n",
        "        assistant_response = full_output.split(\"<|im_start|>assistant\")[-1]\n",
        "        assistant_response = assistant_response.split(\"<|im_end|>\")[0].strip()\n",
        "    except:\n",
        "        assistant_response = full_output.split(\"assistant\")[-1].strip()\n",
        "\n",
        "    # Parse JSON\n",
        "    try:\n",
        "        result = json.loads(assistant_response)\n",
        "        return result.get(\"label\", \"unknown\")\n",
        "    except:\n",
        "        # Fallback: search for label\n",
        "        for label in [\"emotional_support\", \"informational\", \"complex_consultation\", \"high_risk\"]:\n",
        "            if label in assistant_response.lower():\n",
        "                return label\n",
        "        return \"unknown\"\n",
        "\n",
        "print(\"‚úÖ Prediction function defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dcSB06sJa2v",
        "outputId": "c5b66761-2b4c-44ce-f94b-d32099178097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prediction function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 10: Evaluate on full test set\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä FULL EVALUATION ON TEST SET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load test data\n",
        "test_file = \"/content/drive/MyDrive/Major/Text_Reasoning/Text_Reasoning_test.jsonl\"\n",
        "\n",
        "print(f\"üìÇ Loading test data: {test_file}\")\n",
        "with open(test_file, 'r', encoding='utf-8') as f:\n",
        "    test_samples = [json.loads(line) for line in f]\n",
        "\n",
        "print(f\"üìä Total test samples: {len(test_samples)}\")\n",
        "\n",
        "# Run predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "print(\"\\nüöÄ Running predictions...\")\n",
        "for sample in tqdm(test_samples):\n",
        "    text = sample['text']\n",
        "    true_label = sample['label']\n",
        "\n",
        "    pred_label = predict_intent(text)\n",
        "\n",
        "    y_true.append(true_label)\n",
        "    y_pred.append(pred_label)\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üèÜ EVALUATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"\\n‚úÖ Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "print(\"\\nüìÑ Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4, zero_division=0))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nüìä Confusion Matrix:\")\n",
        "labels = [\"emotional_support\", \"informational\", \"complex_consultation\", \"high_risk\"]\n",
        "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "print(\"\\n                    Predicted ‚Üí\")\n",
        "print(\"True ‚Üì        Emotional   Info   Complex   HighRisk\")\n",
        "for i, label in enumerate([\"Emotional\", \"Info\", \"Complex\", \"HighRisk\"]):\n",
        "    print(f\"{label:12}\", end=\"  \")\n",
        "    for j in range(4):\n",
        "        print(f\"{cm[i][j]:8}\", end=\"  \")\n",
        "    print()\n",
        "\n",
        "# Sample errors\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîç SAMPLE ERRORS (First 10)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "error_count = 0\n",
        "for i in range(len(y_true)):\n",
        "    if y_true[i] != y_pred[i]:\n",
        "        print(f\"\\n‚ùå Error #{error_count + 1}\")\n",
        "        print(f\"   Input: {test_samples[i]['text'][:70]}...\")\n",
        "        print(f\"   True:  {y_true[i]:25}\")\n",
        "        print(f\"   Pred:  {y_pred[i]:25}\")\n",
        "        error_count += 1\n",
        "        if error_count >= 10:\n",
        "            break\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"‚úÖ FINAL ACCURACY: {acc*100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s38QeBF9Jcc7",
        "outputId": "b99acf3a-2f00-4400-97f6-5c533d54a7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üìä FULL EVALUATION ON TEST SET\n",
            "============================================================\n",
            "üìÇ Loading test data: /content/drive/MyDrive/Major/Text_Reasoning/Text_Reasoning_test.jsonl\n",
            "üìä Total test samples: 565\n",
            "\n",
            "üöÄ Running predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 565/565 [06:51<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üèÜ EVALUATION RESULTS\n",
            "============================================================\n",
            "\n",
            "‚úÖ Accuracy: 1.0000 (100.00%)\n",
            "------------------------------------------------------------\n",
            "\n",
            "üìÑ Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "complex_consultation     1.0000    1.0000    1.0000       120\n",
            "   emotional_support     1.0000    1.0000    1.0000       252\n",
            "           high_risk     1.0000    1.0000    1.0000        87\n",
            "       informational     1.0000    1.0000    1.0000       106\n",
            "\n",
            "            accuracy                         1.0000       565\n",
            "           macro avg     1.0000    1.0000    1.0000       565\n",
            "        weighted avg     1.0000    1.0000    1.0000       565\n",
            "\n",
            "\n",
            "üìä Confusion Matrix:\n",
            "\n",
            "                    Predicted ‚Üí\n",
            "True ‚Üì        Emotional   Info   Complex   HighRisk\n",
            "Emotional          252         0         0         0  \n",
            "Info                 0       106         0         0  \n",
            "Complex              0         0       120         0  \n",
            "HighRisk             0         0         0        87  \n",
            "\n",
            "============================================================\n",
            "üîç SAMPLE ERRORS (First 10)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "‚úÖ FINAL ACCURACY: 100.00%\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RlNq-L-pJkeP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}