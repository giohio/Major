import json
import random
import os
from pathlib import Path

# ==============================================================================
# 1. CONFIGURATION
# ==============================================================================
SCRIPT_DIR = Path(__file__).parent.resolve()
TARGET_TOTAL = 6000       
TRAIN_RATIO = 0.9         
OUTPUT_TRAIN = SCRIPT_DIR / "../../data/test_sets/Text_Reasoning/Text_Reasoning_train.jsonl"
OUTPUT_TEST = SCRIPT_DIR / "../../data/test_sets/Text_Reasoning/Text_Reasoning_test.jsonl"

(SCRIPT_DIR / "../../data/test_sets/Text_Reasoning/").mkdir(parents=True, exist_ok=True)

DISTRIBUTION = {
    "emotional_support": 0.40,
    "informational": 0.25,
    "complex_consultation": 0.25,  # Increased from 0.20
    "high_risk": 0.10              # Decreased from 0.15
}

print("üîß Fixed Data Generator V4 - Disambiguated Contexts")
print(f"üéØ Target: {TARGET_TOTAL} samples")

# ==============================================================================
# VOCABULARY (SEPARATED POOLS)
# ==============================================================================

pronouns = [
    "Em", "M√¨nh", "T·ªõ", "Con", "T√¥i", "Anh", "Ch·ªã", "Ch√°u"
]

timeframes = [
    "d·∫°o n√†y", "m·∫•y h√¥m nay", "g·∫ßn ƒë√¢y", "su·ªët tu·∫ßn", 
    "t·ª´ h√¥m qua", "t·ª± d∆∞ng", "c·∫£ th√°ng nay"
]

# EMOTIONAL SUPPORT
emo_feelings = [
    "bu·ªìn", "ch√°n", "m·ªát m·ªèi", "c√¥ ƒë∆°n", "√°p l·ª±c", 
    "stress", "t·ªßi th√¢n", "tr·ªëng r·ªóng", "b·∫•t l·ª±c"
]

emo_causes = [
    "b·ªã s·∫øp m·∫Øng", "v·ª´a chia tay", "thi tr∆∞·ª£t", "m·∫•t vi·ªác",
    "c√£i nhau v·ªõi b·∫°n", "b·ªë m·∫π kh√¥ng hi·ªÉu", "deadline d√≠",
    "crush c√≥ ng∆∞·ªùi y√™u", "b·ªã b·∫°n xa l√°nh"
]

# INFORMATIONAL
info_concepts = [
    "tr·∫ßm c·∫£m", "lo √¢u", "r·ªëi lo·∫°n l∆∞·ª°ng c·ª±c", "OCD", "PTSD",
    "m·∫•t ng·ªß", "stress", "burnout", "r·ªëi lo·∫°n ƒÉn u·ªëng", "ADHD"
]

info_queries = [
    "l√† g√¨", "c√≥ tri·ªáu ch·ª©ng g√¨", "nguy hi·ªÉm kh√¥ng", 
    "ch·ªØa th·∫ø n√†o", "d√πng thu·ªëc g√¨", "c√≥ di truy·ªÅn kh√¥ng"
]

# COMPLEX CONSULTATION (Medical contexts - SEPARATED)
complex_symptoms = [
    "m·∫•t ng·ªß", "tim ƒë·∫≠p nhanh", "ƒëau ƒë·∫ßu", "run tay",
    "kh√≥ th·ªü", "s·ª•t c√¢n", "ƒÉn kh√¥ng ngon", "hay qu√™n",
    "c√°u g·∫Øt", "s·ª£ ƒë√°m ƒë√¥ng", "kh√¥ng t·∫≠p trung"
]

# ‚≠ê SEPARATED: Medical/Physical contexts (NOT emotional)
complex_contexts = [
    "sau sinh em b√©",
    "t·ª´ l√∫c b·ªã tai n·∫°n giao th√¥ng",
    "sau ph·∫´u thu·∫≠t",
    "d√πng thu·ªëc tr√°nh thai",
    "thay ƒë·ªïi m√¥i tr∆∞·ªùng s·ªëng",
    "chuy·ªÉn c√¥ng vi·ªác m·ªõi",
    "sau ƒë·ª£t thi ƒë·∫°i h·ªçc",
    "m√£n kinh",
    "d√πng thu·ªëc ƒëi·ªÅu tr·ªã b·ªánh kh√°c"
]

# Medical framing (NEW)
medical_frames = [
    "B√°c sƒ© ∆°i,",
    "Cho em h·ªèi,",
    "Em ƒëi kh√°m th√¨ b√°c sƒ© n√≥i",
    "Tri·ªáu ch·ª©ng n√†y",
    "Xin t∆∞ v·∫•n,"
]

complex_history = [
    "ƒë√£ ƒëi kh√°m nh∆∞ng kh√¥ng ƒë·ª°",
    "u·ªëng thu·ªëc 2 th√°ng v·∫´n v·∫≠y",
    "th·ª≠ CBT r·ªìi nh∆∞ng kh√¥ng hi·ªáu qu·∫£",
    "x√©t nghi·ªám ƒë·ªÅu b√¨nh th∆∞·ªùng"
]

# HIGH RISK (Emotional/Crisis contexts - SEPARATED)
# ‚≠ê SEPARATED: Emotional/Social crisis (NOT medical)
high_risk_contexts = [
    "b·ªã b·∫Øt n·∫°t li√™n t·ª•c",
    "m·∫•t h·∫øt ti·ªÅn b·∫°c do ƒë√°nh b·∫°c",
    "ng∆∞·ªùi y√™u ph·∫£n b·ªôi",
    "b·ªã sa th·∫£i oan",
    "gia ƒë√¨nh tan v·ª°",
    "b·ªã l·ª´a ti·ªÅn",
    "con b·ªã b·ªánh n·∫∑ng",
    "v·ª° n·ª£",
    "b·ªã t·ªëng giam oan",
    "m·∫•t ng∆∞·ªùi th√¢n ƒë·ªôt ng·ªôt"
]

# ADD: Stressful but medical contexts (for complex)
stress_medical_contexts = [
    "√°p l·ª±c n·ª£ n·∫ßn",
    "√°p l·ª±c c√¥ng vi·ªác qu√° l·ªõn",
    "√°p l·ª±c thi c·ª≠",
    "m√¢u thu·∫´n v·ª£ ch·ªìng k√©o d√†i"
]

risk_subtle = [
    "cu·ªôc s·ªëng v√¥ nghƒ©a",
    "m·ªçi ng∆∞·ªùi t·ªët h∆°n n·∫øu kh√¥ng c√≥ em",
    "mu·ªën ng·ªß m·ªôt gi·∫•c th·∫≠t d√†i",
    "ƒë√£ vi·∫øt th∆∞ cho m·ªçi ng∆∞·ªùi",
    "kh√¥ng c√≤n l√Ω do ƒë·ªÉ ·ªü l·∫°i"
]

risk_explicit = [
    "mu·ªën ch·∫øt", "t·ª± t·ª≠", "u·ªëng thu·ªëc ng·ªß", "nh·∫£y l·∫ßu",
    "r·∫°ch tay", "k·∫øt th√∫c cu·ªôc ƒë·ªùi"
]

# ==============================================================================
# GENERATORS (FIXED)
# ==============================================================================

def gen_emotional_support():
    """Emotional support samples"""
    pronoun = random.choice(pronouns)
    feel = random.choice(emo_feelings)
    cause = random.choice(emo_causes)
    
    styles = [
        f"{feel} qu√°, {cause}",
        f"{cause}, gi·ªù {feel} vcl",
        f"{pronoun} {feel} l·∫Øm, {cause}",
        f"{cause} l√†m {pronoun} {feel}. Ai gi√∫p em v·ªõi"
    ]
    
    return random.choice(styles)

def gen_informational():
    """Informational queries"""
    concept = random.choice(info_concepts)
    query = random.choice(info_queries)
    
    if random.random() < 0.5:
        contexts = [
            f"B√°c sƒ© n√≥i em b·ªã {concept}",
            f"Em hay {random.choice(emo_feelings)}",
            f"Ng∆∞·ªùi th√¢n em c√≥ d·∫•u hi·ªáu {concept}"
        ]
        return f"{random.choice(contexts)}, {query}?"
    else:
        prefixes = ["", "Cho h·ªèi ", "M·ªçi ng∆∞·ªùi ∆°i "]
        return f"{random.choice(prefixes)}{concept} {query}?"

def gen_complex_consultation():
    """
    Complex consultation with MEDICAL contexts
    Key fix: Add medical framing + separated contexts
    """
    pronoun = random.choice(pronouns)
    symp = random.choice(complex_symptoms)
    
    # 40%: Pure medical contexts
    if random.random() < 0.4:
        ctx = random.choice(complex_contexts)
        frame = random.choice(medical_frames)
        
        if random.random() < 0.5:
            history = random.choice(complex_history)
            return f"{frame} {ctx}, {pronoun} {symp}. {history}, c√≥ ph·∫£i b·ªánh kh√¥ng?"
        else:
            return f"{frame} {ctx} l√†m {pronoun} b·ªã {symp}. N√™n kh√°m chuy√™n khoa n√†o?"
    
    # 40%: Stress contexts with CLEAR medical framing (FIX for "√°p l·ª±c n·ª£ n·∫ßn")
    elif random.random() < 0.8:
        ctx = random.choice(stress_medical_contexts)
        frame = random.choice(medical_frames)
        
        templates = [
            f"{frame} do {ctx}, em b·ªã {symp}. C√≥ ph·∫£i r·ªëi lo·∫°n lo √¢u kh√¥ng?",
            f"{frame} {ctx} l√†m em {symp} su·ªët. ƒê√£ kh√°m nh∆∞ng kh√¥ng r√µ nguy√™n nh√¢n?",
            f"Do stress v√¨ {ctx}, em xu·∫•t hi·ªán tri·ªáu ch·ª©ng {symp}. Xin t∆∞ v·∫•n?",
            f"B√°c sƒ© ∆°i, {ctx} khi·∫øn em {symp} k√©o d√†i {random.choice(['2 tu·∫ßn', '1 th√°ng'])}. C√≥ c·∫ßn d√πng thu·ªëc kh√¥ng?"
        ]
        return random.choice(templates)
    
    # 20%: Multiple symptoms
    else:
        ctx = random.choice(complex_contexts + stress_medical_contexts)
        symp2 = random.choice([s for s in complex_symptoms if s != symp])
        return f"{ctx}, {pronoun} v·ª´a {symp} v·ª´a {symp2}. B√°c sƒ© ch·∫©n ƒëo√°n gi√∫p em?"

def gen_high_risk():
    """
    High risk samples with EMOTIONAL/CRISIS contexts only
    Key fix: Use separated high_risk_contexts (no medical overlap)
    """
    pronoun = random.choice(pronouns)
    
    # 70%: Subtle/Implicit
    if random.random() < 0.7:
        context = random.choice(high_risk_contexts)  # ‚Üê SEPARATED pool
        trigger = random.choice(risk_subtle)
        base = random.choice([
            f"{pronoun} c·∫£m th·∫•y cu·ªôc s·ªëng v√¥ nghƒ©a",
            f"{pronoun} m·ªát m·ªèi qu√° r·ªìi",
            "L√†m g√¨ c≈©ng sai"
        ])
        
        return f"{base} do {context}. {trigger}"
    
    # 30%: Semi-explicit with crisis context
    else:
        context = random.choice(high_risk_contexts)  # ‚Üê SEPARATED pool
        trigger = random.choice(risk_explicit)
        emotion = random.choice(emo_feelings)
        
        return f"{context}, {pronoun} {emotion} v√† mu·ªën {trigger}. Xin l·ªói m·ªçi ng∆∞·ªùi"

# ==============================================================================
# MAIN PROCESS
# ==============================================================================

def main():
    data = []
    seen_hashes = set()
    
    generators = {
        "emotional_support": gen_emotional_support,
        "informational": gen_informational,
        "complex_consultation": gen_complex_consultation,
        "high_risk": gen_high_risk
    }

    print("\n‚è≥ Generating dataset with fixed context separation...")
    
    for label, ratio in DISTRIBUTION.items():
        target_count = int(TARGET_TOTAL * ratio)
        print(f"   üîπ Generating {label}: Target {target_count}...")
        
        count = 0
        attempts = 0
        max_attempts = target_count * 100
        
        while count < target_count and attempts < max_attempts:
            text = generators[label]()
            text = " ".join(text.split()).strip()
            
            if text not in seen_hashes:
                data.append({"text": text, "label": label})
                seen_hashes.add(text)
                count += 1
            
            attempts += 1
        
        print(f"   ‚úÖ Generated {count} samples")

    # Shuffle and split
    random.shuffle(data)
    split_idx = int(len(data) * TRAIN_RATIO)
    train_data = data[:split_idx]
    test_data = data[split_idx:]

    # Save
    with open(OUTPUT_TRAIN, "w", encoding="utf-8") as f:
        for entry in train_data:
            json.dump(entry, f, ensure_ascii=False)
            f.write("\n")
    
    with open(OUTPUT_TEST, "w", encoding="utf-8") as f:
        for entry in test_data:
            json.dump(entry, f, ensure_ascii=False)
            f.write("\n")

    # Stats
    from collections import Counter
    counts = Counter([d['label'] for d in data])
    
    print("\n" + "="*60)
    print(f"üéâ COMPLETE! Generated {len(data)} samples")
    print(f"üìÅ Train: {len(train_data)} | Test: {len(test_data)}")
    print("\nüìä Label distribution:")
    for label, count in counts.items():
        print(f"   {label:25} {count:5} ({count/len(data)*100:.1f}%)")
    print("="*60)
    
    # Validate separation
    print("\nüîç Context separation check:")
    medical_in_high_risk = sum(1 for d in data if d['label'] == 'high_risk' and 
                                any(ctx in d['text'] for ctx in complex_contexts))
    crisis_in_complex = sum(1 for d in data if d['label'] == 'complex_consultation' and 
                            any(ctx in d['text'] for ctx in high_risk_contexts))
    
    print(f"   Medical contexts in high_risk: {medical_in_high_risk} (should be ~0)")
    print(f"   Crisis contexts in complex: {crisis_in_complex} (should be ~0)")

if __name__ == "__main__":
    main()